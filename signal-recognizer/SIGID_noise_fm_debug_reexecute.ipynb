{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SIGID-noise-fm-debug-reexecute.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7pwwrG_z9XD",
        "colab_type": "text"
      },
      "source": [
        "Laburanding en ver de diferenciar una senial de noise de una de FM, para luego extender a varias mas. Version para re ejecutar y dejar el mejor.\n",
        "\n",
        "Data logged using:\n",
        "uhd_ -f -b \n",
        "\n",
        "**Se ajusto todo para debuggear porque no sale de .5 accuracy, ver problema.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdSC_l0QBfZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras.layers import TimeDistributed, LSTM, Dropout, Conv1D, Dense, Activation, MaxPooling1D, Input\n",
        "from tensorflow.keras.utils import Sequence as Sequence\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from datetime import datetime\n",
        "import ast\n",
        "\n",
        "sample_rate = 100000\n",
        "signals_count = 2\n",
        "epochs = 20\n",
        "batch_size = 128\n",
        "capture_size = 2048\n",
        "\n",
        "# Debug\n",
        "#train_size = 16\n",
        "#test_size = 4\n",
        "#capture_size = 8\n",
        "# Test\n",
        "#train_size = 50\n",
        "#test_size = 5\n",
        "# Real\n",
        "train_size = 1000\n",
        "test_size = 200\n",
        "\n",
        "dir_base_model = \"/content/gdrive/My Drive/DeepLearning/sigid/test-\"\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pSRLW-swqu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Create a dtype with the binary data format and the desired column names\n",
        "dt = np.dtype([('i', 'f4'), ('q', 'f4')])\n",
        "# Load noisy data\n",
        "data = np.fromfile(dir_base_model + \"nothing.iq\", dtype=dt)\n",
        "dfa = pd.DataFrame(data)\n",
        "dfa[\"label\"] = \"BLANK\"\n",
        "npArray = np.array(range(len(dfa)), dtype='f4', copy=True, order='K', subok=False, ndmin=0)\n",
        "dfa[\"time\"] = npArray / sample_rate\n",
        "# Load FM data\n",
        "data = np.fromfile(dir_base_model + \"999.iq\", dtype=dt)\n",
        "dfb = pd.DataFrame(data)\n",
        "dfb[\"label\"] = \"FM\"\n",
        "npArray = np.array(range(len(dfb)), dtype='f4', copy=True, order='K', subok=False, ndmin=0)\n",
        "dfb[\"time\"] = npArray / sample_rate\n",
        "\n",
        "frames = [dfa, dfb]\n",
        "result = pd.concat(frames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzG66vrpyfhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = []\n",
        "test = []\n",
        "\n",
        "# Build datasets for train \n",
        "for i in (0, train_size):\n",
        "  ii = i * capture_size\n",
        "  train.append(dfa[ii:ii + capture_size].values)\n",
        "for i in (0, train_size):\n",
        "  ii = i * capture_size\n",
        "  train.append(dfb[ii:ii + capture_size].values)\n",
        "\n",
        "# Build datasets for test \n",
        "for i in (0, test_size):\n",
        "  ii = i * capture_size\n",
        "  test.append(dfa[ii:ii + capture_size].values)\n",
        "for i in (0, test_size):\n",
        "  ii = i * capture_size\n",
        "  test.append(dfb[ii:ii + capture_size].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRUQTgUr8p9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Capture size dfa BLANK: ' + str(len(dfa.values)))\n",
        "print('Capture size dfb FM: ' + str(len(dfb.values)))\n",
        "#print(dfa[1:capture_size]['i'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIKmeEHkJmS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=dfa[1:capture_size]['time'], y=dfa[1:capture_size]['i'], mode='lines', name='i'))\n",
        "fig.add_trace(go.Scatter(x=dfa[1:capture_size]['time'], y=dfa[1:capture_size]['q'], mode='lines', name='q'))\n",
        "fig.update_layout(\n",
        "    title=\"NOISE\",\n",
        "    xaxis_title=\"time\",\n",
        "    yaxis_title=\"value\",\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=18,\n",
        "        color=\"#7f7f7f\"\n",
        "    )\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=dfb[1:capture_size]['time'], y=dfb[1:capture_size]['i'], mode='lines', name='i'))\n",
        "fig.add_trace(go.Scatter(x=dfb[1:capture_size]['time'], y=dfb[1:capture_size]['q'], mode='lines', name='q'))\n",
        "fig.update_layout(\n",
        "    title=\"FM\",\n",
        "    xaxis_title=\"time\",\n",
        "    yaxis_title=\"value\",\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=18,\n",
        "        color=\"#7f7f7f\"\n",
        "    )\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEcc_eOioZZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfa[1:capture_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmXGfsTfTyHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot some sample data to check iq files\n",
        "import plotly.express as px\n",
        "interleave = 2\n",
        "fig = px.line(dfa[1+train_size * interleave + capture_size:capture_size], x=\"time\", y=\"i\", labels={'X':'I'}, width=1000, height=300)\n",
        "fig.show()\n",
        "fig = px.line(dfb[1+train_size * interleave + capture_size:capture_size], x=\"time\", y=\"i\", labels={'X':'I'}, width=1000, height=300)\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D40kVty0h_8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_signal_dataframes(df):\n",
        "  interleave = 2\n",
        "  dx = []\n",
        "  dy = []\n",
        "  tx = []\n",
        "  ty = []\n",
        "\n",
        "  # Generate train dataset \n",
        "  dfax = df[['i', 'q']] \n",
        "  dfay = df[['label']] \n",
        "  dfax = dfax * 10000.0\n",
        "  for i in range(0, train_size):\n",
        "    newx = dfax[interleave * i:interleave * i + capture_size]\n",
        "    dx.append(newx)    \n",
        "    newy = dfay[interleave * i:interleave * i + capture_size]\n",
        "    dy.append(newy)\n",
        "\n",
        "  # Offset to separate train from test datain df\n",
        "  offset = train_size * interleave + capture_size\n",
        "\n",
        "  print(\"Offset \" + str(offset))\n",
        "\n",
        "  # Generate test dataset \n",
        "  for i in range(0, test_size):\n",
        "    newx = dfax[interleave * i + offset:interleave * i + capture_size + offset]\n",
        "    tx.append(newx)\n",
        "    newy = dfay[interleave * i + offset:interleave * i + capture_size + offset]\n",
        "    ty.append(newy)\n",
        "\n",
        "  # Convert lists to dataframes\n",
        "  train_x = pd.DataFrame(dx) \n",
        "  train_y = pd.DataFrame(dy) \n",
        "  test_x = pd.DataFrame(tx) \n",
        "  test_y = pd.DataFrame(ty) \n",
        "  return train_x, train_y, test_x, test_y\n",
        "\n",
        "def add_dataframe_for_signal(df, train_x, train_y, test_x, test_y):\n",
        "  x, y, tx, ty = get_signal_dataframes(df)\n",
        "  train_x.append(x)\n",
        "  train_y.append(y)\n",
        "  test_x.append(tx)\n",
        "  test_y.append(ty)\n",
        "\n",
        "train_x = []\n",
        "train_y = []\n",
        "test_x = []\n",
        "test_y = []\n",
        "add_dataframe_for_signal(dfa, train_x, train_y, test_x, test_y)\n",
        "add_dataframe_for_signal(dfb, train_x, train_y, test_x, test_y)\n",
        "\n",
        "# Build dataframes \n",
        "train_x = pd.concat(train_x)\n",
        "train_y = pd.concat(train_y)\n",
        "test_x = pd.concat(test_x)\n",
        "test_y = pd.concat(test_y)\n",
        "\n",
        "# Shuffle data\n",
        "permutations = np.random.permutation(len(train_y))\n",
        "train_x = train_x.iloc[permutations]\n",
        "train_y = train_y.iloc[permutations]\n",
        "permutations = np.random.permutation(len(test_x))\n",
        "test_x = test_x.iloc[permutations]\n",
        "test_y = test_y.iloc[permutations]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vaj31Pv0DW7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recreate_np_array_x(d, size):\n",
        "  new = np.ndarray(shape=(signals_count * size, 2, capture_size), dtype=float)\n",
        "  # train or test size i\n",
        "  for i in range(len(d.values)):\n",
        "    # 2048 j\n",
        "    for j in range(len((d.values)[i])):\n",
        "        new[i][0][j] = ((d.values)[i])[0].values[j][0]\n",
        "        new[i][1][j] = ((d.values)[i])[0].values[j][1]\n",
        "  return new\n",
        "\n",
        "def recreate_np_array_y(d, size):\n",
        "  new = np.ndarray(shape=(signals_count * size), dtype=np.int16)\n",
        "  # 100 i\n",
        "  for i in range(len(d.values)):\n",
        "    result = ((d.values)[i])[0].values[0][0]\n",
        "    if (result == 'FM'):\n",
        "      new[i] = 1\n",
        "    else:\n",
        "      new[i] = 0\n",
        "  return new\n",
        "\n",
        "train_x = recreate_np_array_x(train_x, train_size)\n",
        "train_y = recreate_np_array_y(train_y, train_size)\n",
        "test_x = recreate_np_array_x(test_x, test_size)\n",
        "test_y = recreate_np_array_y(test_y, test_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XAgG58D56vJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Real model to test: .771 accuracay\n",
        "def model_original():\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(filters=10, kernel_size=16, strides=1, padding='same', activation='relu', input_shape=(2, capture_size)))\n",
        "  model.add(MaxPooling1D(pool_size=10, strides=2, padding='same'))\n",
        "  model.add(Conv1D(filters=10, kernel_size=12, strides=1, padding='same', activation='relu', input_shape=(6, int(capture_size / 2))))\n",
        "  model.add(MaxPooling1D(pool_size=10, strides=2, padding='same'))\n",
        "  model.add(Conv1D(filters=10, kernel_size=6, strides=1, padding='same', activation='relu', input_shape=(6, int(capture_size / 4))))\n",
        "  model.add(MaxPooling1D(pool_size=10, strides=2, padding='same'))\n",
        "  model.add(Conv1D(filters=10, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=(6, int(capture_size / 8))))\n",
        "  model.add(MaxPooling1D(pool_size=10, strides=2, padding='same'))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# Real model to test: .805 accuracay\n",
        "def model_test():\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(filters=10, kernel_size=8, strides=3, padding='same', activation='relu', input_shape=(2, capture_size)))\n",
        "  model.add(MaxPooling1D(pool_size=10, strides=2, padding='same'))\n",
        "  model.add(Dense(20, activation='relu'))\n",
        "  model.add(Conv1D(filters=10, kernel_size=12, strides=1, padding='same', activation='relu', input_shape=(6, int(capture_size / 2))))\n",
        "  model.add(MaxPooling1D(pool_size=10, strides=2, padding='same'))\n",
        "  model.add(Dense(20, activation='relu'))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWdtNiyxWg6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_last_model():\n",
        "  model = tf.keras.models.load_model(dir_base_model + 'best-noise-vs-fm-info-best.model')\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsWebY1bMj5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tensorboard test\n",
        "from datetime import datetime\n",
        "logdir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI89x6H0CsnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #TODO: Contar los distintos labels de los df\n",
        "#model = model_original()\n",
        "model = load_last_model()\n",
        "model.summary()\n",
        "\n",
        "# Train\n",
        "model.fit(x = train_x, y = train_y, batch_size=batch_size, verbose=1, validation_data=(test_x, test_y), epochs=60, callbacks=[tensorboard_callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai9zKrqhhf80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_saved_info():\n",
        "  try:\n",
        "      file = open(dir_base_model + 'best-noise-vs-fm-info-best.txt', 'rt')\n",
        "      value = file.read()\n",
        "      print(value)\n",
        "      file.close()\n",
        "      old_evaluation_result = ast.literal_eval(value)\n",
        "      return old_evaluation_result\n",
        "  except FileNotFoundError:\n",
        "      return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxiyvBKCgt9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate model\n",
        "evaluation_result = model.evaluate(test_x, test_y, verbose=1)\n",
        "print(evaluation_result)\n",
        "print(\"Current loss is: \" + str(evaluation_result))\n",
        "\n",
        "old_evaluation_result = read_saved_info()\n",
        "exists = False\n",
        "print(\"Old loss is: \" + str(old_evaluation_result))\n",
        "if (old_evaluation_result != None):\n",
        "  exists = True\n",
        "\n",
        "if (exists == False or (evaluation_result[1] > old_evaluation_result[1])):\n",
        "  print(\"Writting new object becauce of better validation accuracy...\")\n",
        "  file = open(dir_base_model + 'best-noise-vs-fm-info-best.txt', 'wt')\n",
        "  file.write(str(evaluation_result))\n",
        "  file.close()\n",
        "  model.save(dir_base_model + 'best-noise-vs-fm-info-best.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUKBKR_0jmK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare one line of data to predict\n",
        "iv = test_x[0][0]\n",
        "qv = test_x[0][1]\n",
        "element = 0\n",
        "\n",
        "td = np.ndarray(shape=(2, 2, capture_size), dtype=float)\n",
        "for j in range(10):\n",
        "  for i in range(len(iv)):\n",
        "    td[0][0][i] = test_x[element+j][0][i]\n",
        "    td[0][1][i] = test_x[element+j][1][i]\n",
        "\n",
        "rd = np.ndarray(shape=(2, 2, capture_size), dtype=float)\n",
        "for j in range(10):\n",
        "  for i in range(len(iv)):\n",
        "    rd[0][0][i] = test_y[element+j][0][i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY6GbFOBp_nV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(td)\n",
        "print(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IevSiFy9wUNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Draw confusion matrix\n",
        "# https://plot.ly/~francoisp/50/confusion-matrix/#code\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}